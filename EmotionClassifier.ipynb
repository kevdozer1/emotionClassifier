{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNosViVhBJ4ks/yzjOJ2JLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevdozer1/emotionClassifier/blob/main/EmotionClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project revolves around multimodal emotion classification, incorporating data from three distinct modalities: vision, speech, and text. The goal is to detect and categorize human emotions into four primary classes, utilizing an extensive array of data processing, feature extraction, and machine learning techniques. Different methods for pooling and temporal modeling are employed to address the temporal dimension in audio and visual files. Various classifiers are applied for emotion classification, with the most effective parameters selected via Grid Search. The project also addresses class imbalance and applies both early and late fusion techniques to yield optimal results. A thorough evaluation and interpretation of the unimodal and multimodal classification tasks informs better performance."
      ],
      "metadata": {
        "id": "t-WwiQaq7gYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "tN2XYeYpyfWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330d8f9f-c753-4381-ca82-355fc635d0ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fMr0Xc_2yaGh"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset.csv as a pandas dataframe\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/dataset.csv')"
      ],
      "metadata": {
        "id": "3B3Eeziq0z0n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 rows of the dataframe\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg7YrQlA01O9",
        "outputId": "8b8d2ce9-c7ad-4fbb-b4a0-d4b709979233"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        file_name_list speakers  \\\n",
            "0  Ses01F_impro01_F001      F01   \n",
            "1  Ses01F_impro01_M011      M01   \n",
            "2  Ses01F_impro02_F002      F01   \n",
            "3  Ses01F_impro02_F003      F01   \n",
            "4  Ses01F_impro02_F004      F01   \n",
            "\n",
            "                                     visual_features  \\\n",
            "0  /features/visual_features/Session1/Ses01F_impr...   \n",
            "1  /features/visual_features/Session1/Ses01F_impr...   \n",
            "2  /features/visual_features/Session1/Ses01F_impr...   \n",
            "3  /features/visual_features/Session1/Ses01F_impr...   \n",
            "4  /features/visual_features/Session1/Ses01F_impr...   \n",
            "\n",
            "                                   acoustic_features  \\\n",
            "0  /features/acoustic_features/Session1/Ses01F_im...   \n",
            "1  /features/acoustic_features/Session1/Ses01F_im...   \n",
            "2  /features/acoustic_features/Session1/Ses01F_im...   \n",
            "3  /features/acoustic_features/Session1/Ses01F_im...   \n",
            "4  /features/acoustic_features/Session1/Ses01F_im...   \n",
            "\n",
            "                                    lexical_features  emotion_labels  \n",
            "0  /features/lexical_features/Session1/Ses01F_imp...               3  \n",
            "1  /features/lexical_features/Session1/Ses01F_imp...               0  \n",
            "2  /features/lexical_features/Session1/Ses01F_imp...               1  \n",
            "3  /features/lexical_features/Session1/Ses01F_imp...               3  \n",
            "4  /features/lexical_features/Session1/Ses01F_imp...               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the files in the features folder\n",
        "import os\n",
        "files = os.listdir('/content/gdrive/MyDrive/features')\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMKX1tX12NWC",
        "outputId": "6c34cedd-7fe2-4dc4-9bd7-b460867e4bfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['visual_features', 'acoustic_features', 'lexical_features']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['visual_features'] = df['visual_features'].str.lstrip('/')\n",
        "df['acoustic_features'] = df['acoustic_features'].str.lstrip('/')\n",
        "df['lexical_features'] = df['lexical_features'].str.lstrip('/')"
      ],
      "metadata": {
        "id": "Hi070HvP3655"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_features(df):\n",
        "    visual_features = []\n",
        "    acoustic_features = []\n",
        "    lexical_features = []\n",
        "\n",
        "    total_rows = df.shape[0]\n",
        "\n",
        "    for i, (_, row) in enumerate(df.iterrows()):\n",
        "        visual = np.load(os.path.join('/content/gdrive/MyDrive', row['visual_features']))\n",
        "        acoustic = np.load(os.path.join('/content/gdrive/MyDrive', row['acoustic_features']))\n",
        "        lexical = np.load(os.path.join('/content/gdrive/MyDrive', row['lexical_features']))\n",
        "\n",
        "        visual_features.append(visual)\n",
        "        acoustic_features.append(acoustic)\n",
        "        lexical_features.append(lexical)\n",
        "\n",
        "        if i % 100 == 0:  # print progress every 100 rows\n",
        "            print(f'Processed {i} of {total_rows} rows.')\n",
        "\n",
        "    return visual_features, acoustic_features, lexical_features\n",
        "\n",
        "visual_features, acoustic_features, lexical_features = load_features(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJKf6uE72QXB",
        "outputId": "25b7e7d5-fbb3-48cd-a3ba-c5436bdf1391"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 of 1336 rows.\n",
            "Processed 100 of 1336 rows.\n",
            "Processed 200 of 1336 rows.\n",
            "Processed 300 of 1336 rows.\n",
            "Processed 400 of 1336 rows.\n",
            "Processed 500 of 1336 rows.\n",
            "Processed 600 of 1336 rows.\n",
            "Processed 700 of 1336 rows.\n",
            "Processed 800 of 1336 rows.\n",
            "Processed 900 of 1336 rows.\n",
            "Processed 1000 of 1336 rows.\n",
            "Processed 1100 of 1336 rows.\n",
            "Processed 1200 of 1336 rows.\n",
            "Processed 1300 of 1336 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check lengths of the lists\n",
        "print(f\"Visual features list length: {len(visual_features)}\")\n",
        "print(f\"Acoustic features list length: {len(acoustic_features)}\")\n",
        "print(f\"Lexical features list length: {len(lexical_features)}\")\n",
        "\n",
        "# Check shapes of the first items in the lists\n",
        "print(f\"Visual features shape of first item: {visual_features[0].shape}\")\n",
        "print(f\"Acoustic features shape of first item: {acoustic_features[0].shape}\")\n",
        "print(f\"Lexical features shape of first item: {lexical_features[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW-aDDoDBFez",
        "outputId": "c345760c-b9fc-43b8-e796-0e5f1f674f4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual features list length: 1336\n",
            "Acoustic features list length: 1336\n",
            "Lexical features list length: 1336\n",
            "Visual features shape of first item: (41, 2048)\n",
            "Acoustic features shape of first item: (1, 128)\n",
            "Lexical features shape of first item: (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null or NaN values\n",
        "print(f\"NaN in visual features: {any(np.isnan(feature).any() for feature in visual_features)}\")\n",
        "print(f\"NaN in acoustic features: {any(np.isnan(feature).any() for feature in acoustic_features)}\")\n",
        "print(f\"NaN in lexical features: {any(np.isnan(feature).any() for feature in lexical_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb7hrsQjDn-5",
        "outputId": "5ceb8247-d86d-408c-b366-cc27f6698b4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN in visual features: False\n",
            "NaN in acoustic features: False\n",
            "NaN in lexical features: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an index for visual inspection\n",
        "index = np.random.randint(len(visual_features))\n",
        "\n",
        "print(f\"Visual features for sample {index}: {visual_features[index]}\")\n",
        "#print(f\"Acoustic features for sample {index}: {acoustic_features[index]}\")\n",
        "#print(f\"Lexical features for sample {index}: {lexical_features[index]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzbOWix9Dv4b",
        "outputId": "b87498c6-5671-4ba2-f569-e91dcf9ca3d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual features for sample 1172: [[ 1.00270808  0.96876654  0.89850952 ...  0.07428324 -0.37180195\n",
            "   1.32481071]\n",
            " [ 0.36008307 -1.33553001 -0.87943405 ... -1.11682578  1.42930601\n",
            "  -0.5526613 ]\n",
            " [ 1.41106191  0.28784597 -0.18913832 ...  0.55525576 -0.89002935\n",
            "   0.08535146]\n",
            " ...\n",
            " [-1.46517442 -0.47017226  1.33739184 ...  1.00652702  0.34805247\n",
            "   0.8450389 ]\n",
            " [-0.20217286  0.75803373 -0.69424931 ... -0.46562672  1.04470879\n",
            "   1.32293726]\n",
            " [-1.06050635  0.25819745  1.22017409 ... -0.94815652 -1.45079828\n",
            "   2.14136204]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a row from the DataFrame to compare with\n",
        "row = df.iloc[index]\n",
        "\n",
        "# Manually load the features\n",
        "visual_manual = np.load(os.path.join('/content/gdrive/MyDrive', row['visual_features']))\n",
        "acoustic_manual = np.load(os.path.join('/content/gdrive/MyDrive', row['acoustic_features']))\n",
        "lexical_manual = np.load(os.path.join('/content/gdrive/MyDrive', row['lexical_features']))\n",
        "\n",
        "# Compare the manually loaded features with the loaded features\n",
        "print(f\"Visual features match: {np.allclose(visual_manual, visual_features[index])}\")\n",
        "print(f\"Acoustic features match: {np.allclose(acoustic_manual, acoustic_features[index])}\")\n",
        "print(f\"Lexical features match: {np.allclose(lexical_manual, lexical_features[index])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu_eWIngEOZc",
        "outputId": "181f170e-008a-4ee0-e541-c722da2a8562"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual features match: True\n",
            "Acoustic features match: True\n",
            "Lexical features match: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling and Temporal Modeling: To handle the temporal dimension of audio and visual data effectively, mean pooling is used. Temporal modeling techniques, such as RNNs, GRUs, or LSTMs, might also be considered depending on the dataset and task to generate expressive feature vectors for each data point."
      ],
      "metadata": {
        "id": "T283H0es7wZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(features):\n",
        "    return [np.mean(feature, axis=0) for feature in features]\n",
        "\n",
        "# Apply mean pooling\n",
        "visual_features_pooled = mean_pooling(visual_features)\n",
        "acoustic_features_pooled = mean_pooling(acoustic_features)\n",
        "lexical_features_pooled = mean_pooling(lexical_features)"
      ],
      "metadata": {
        "id": "v1r7FBgIBNI-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all elements in the pooled features lists are 1D arrays\n",
        "print(f\"All elements in visual_features_pooled are 1D: {all(feature.ndim == 1 for feature in visual_features_pooled)}\")\n",
        "print(f\"All elements in acoustic_features_pooled are 1D: {all(feature.ndim == 1 for feature in acoustic_features_pooled)}\")\n",
        "print(f\"All elements in lexical_features_pooled are 1D: {all(feature.ndim == 1 for feature in lexical_features_pooled)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUhrMdKvGXIQ",
        "outputId": "735fcb81-1b19-414b-e9c3-d33f55dcf76c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements in visual_features_pooled are 1D: True\n",
            "All elements in acoustic_features_pooled are 1D: True\n",
            "All elements in lexical_features_pooled are 1D: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually compute the mean for the first feature sequence\n",
        "visual_manual = np.mean(visual_features[0], axis=0)\n",
        "\n",
        "# Compare the manually computed mean with the result of mean_pooling\n",
        "print(f\"Visual features match: {np.allclose(visual_manual, visual_features_pooled[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W9bygRdHL9j",
        "outputId": "2d6b6842-5be9-4328-bc59-08ab5ebabeb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual features match: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists of 1D arrays to 2D arrays\n",
        "visual_features_pooled = np.vstack(visual_features_pooled)\n",
        "acoustic_features_pooled = np.vstack(acoustic_features_pooled)\n",
        "lexical_features_pooled = np.vstack(lexical_features_pooled)"
      ],
      "metadata": {
        "id": "gzNphYKuIA_J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the pooled features\n",
        "features_pooled = np.concatenate((visual_features_pooled, acoustic_features_pooled, lexical_features_pooled), axis=1)"
      ],
      "metadata": {
        "id": "WWXDymLwIDC6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One approach: Using a GRU layer to pool in the temporal dimension\n",
        "\n",
        "# Start by importing the necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']}\n",
        "\n",
        "# Load labels\n",
        "labels = df['emotion_labels'].values"
      ],
      "metadata": {
        "id": "q2CH5ApELQxS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convert your data to PyTorch tensors\n",
        "visual_features = [torch.from_numpy(feat.astype(np.float32)) for feat in visual_features]\n",
        "acoustic_features = [torch.from_numpy(feat.astype(np.float32)) for feat in acoustic_features]\n",
        "lexical_features = [torch.from_numpy(feat.astype(np.float32)) for feat in lexical_features]\n",
        "\n",
        "# Convert labels to encoded labels\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "labels_encoded = torch.tensor(labels_encoded, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "a9WUgX6qLvzp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, visual_features, acoustic_features, lexical_features, labels):\n",
        "        self.visual_features = visual_features\n",
        "        self.acoustic_features = acoustic_features\n",
        "        self.lexical_features = lexical_features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        visual_x = self.visual_features[index]\n",
        "        acoustic_x = self.acoustic_features[index]\n",
        "        lexical_x = self.lexical_features[index]\n",
        "        y = self.labels[index]\n",
        "        return visual_x, acoustic_x, lexical_x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "kz02DpW-LX0c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    batch.sort(key=lambda x: x[0].shape[0], reverse=True)\n",
        "\n",
        "    visual_data, acoustic_data, lexical_data, labels = zip(*batch)\n",
        "\n",
        "        # Pad sequences with 0\n",
        "    visual_data = pad_sequence(visual_data, batch_first=True, padding_value=0)\n",
        "    acoustic_data = pad_sequence(acoustic_data, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Convert other data and labels to tensor\n",
        "    lexical_data = torch.stack(lexical_data)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return visual_data, acoustic_data, lexical_data, labels"
      ],
      "metadata": {
        "id": "AD4FhGgoVnKD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Creating the Datasets\n",
        "dataset = MyDataset(visual_features, acoustic_features, lexical_features, labels_encoded)\n",
        "\n",
        "# Define your ratios for splitting the data\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Make sure the ratios sum to 1\n",
        "assert train_ratio + val_ratio + test_ratio == 1\n",
        "\n",
        "# Calculate lengths of splits\n",
        "total_size = len(dataset)\n",
        "train_size = int(total_size * train_ratio)\n",
        "val_size = int(total_size * val_ratio)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Split the data\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create your DataLoaders\n",
        "batch_size = 64 # Adjustable\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "jDyiwfEnQ6HX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a fully connected layer and softmax for classification\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, visual_input_size, acoustic_input_size, lexical_input_size, hidden_size, output_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.gru_visual = nn.GRU(visual_input_size, hidden_size, batch_first=True)\n",
        "        self.gru_acoustic = nn.GRU(acoustic_input_size, hidden_size, batch_first=True)\n",
        "        self.fc_lexical = nn.Linear(lexical_input_size, hidden_size)\n",
        "        self.fc_output = nn.Linear(hidden_size * 3, output_size)  # Combine outputs from three parts\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, visual_data, acoustic_data, lexical_data):\n",
        "        output_visual, _ = self.gru_visual(visual_data)\n",
        "        output_visual = output_visual[:, -1, :]\n",
        "\n",
        "        output_acoustic, _ = self.gru_acoustic(acoustic_data)\n",
        "        output_acoustic = output_acoustic[:, -1, :]\n",
        "\n",
        "        output_lexical = self.fc_lexical(lexical_data)\n",
        "\n",
        "        # Concatenate last hidden states for fusion\n",
        "        output = torch.cat((output_visual, output_acoustic, output_lexical), dim=1)\n",
        "        output = self.fc_output(output)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "wcaN6vkvRavQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Visual features shape:\", visual_features[0].shape[1])\n",
        "print(\"Acoustic features shape:\", acoustic_features[0].shape[1])\n",
        "print(\"Lexical features shape:\", lexical_features[0].shape[0])  # Use 0th dimension here\n",
        "\n",
        "# 3. Initialize the model\n",
        "# determine input sizes from a single sample\n",
        "visual_input_size = visual_features[0].shape[1]\n",
        "acoustic_input_size = acoustic_features[0].shape[1]\n",
        "lexical_input_size = lexical_features[0].shape[0]  # Use 0th dimension here\n",
        "\n",
        "hidden_size = 32  # start with 32, adjust based on performance\n",
        "\n",
        "# Initialize the model\n",
        "model = MyModel(visual_input_size, acoustic_input_size, lexical_input_size, hidden_size, output_size=len(np.unique(labels_encoded)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1AeD-IDL3xS",
        "outputId": "dfe0f55e-aaef-4973-e705-75d2edf3f6cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual features shape: 2048\n",
            "Acoustic features shape: 128\n",
            "Lexical features shape: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define the loss function and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "k98qWvoSL4la"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (visual_data, acoustic_data, lexical_data, labels) in enumerate(train_loader):\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(visual_data, acoustic_data, lexical_data)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print loss every 10 steps\n",
        "        if i % 7 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duKYR671L6li",
        "outputId": "686608ce-c66e-48ac-95da-86f477a282c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [1/15], Loss: 1.3860\n",
            "Epoch [1/20], Step [8/15], Loss: 1.1727\n",
            "Epoch [1/20], Step [15/15], Loss: 1.1368\n",
            "Epoch [2/20], Step [1/15], Loss: 0.9441\n",
            "Epoch [2/20], Step [8/15], Loss: 1.0678\n",
            "Epoch [2/20], Step [15/15], Loss: 0.9233\n",
            "Epoch [3/20], Step [1/15], Loss: 0.8344\n",
            "Epoch [3/20], Step [8/15], Loss: 0.8193\n",
            "Epoch [3/20], Step [15/15], Loss: 0.6259\n",
            "Epoch [4/20], Step [1/15], Loss: 0.6688\n",
            "Epoch [4/20], Step [8/15], Loss: 0.7733\n",
            "Epoch [4/20], Step [15/15], Loss: 0.7037\n",
            "Epoch [5/20], Step [1/15], Loss: 0.7022\n",
            "Epoch [5/20], Step [8/15], Loss: 0.7169\n",
            "Epoch [5/20], Step [15/15], Loss: 0.5195\n",
            "Epoch [6/20], Step [1/15], Loss: 0.5624\n",
            "Epoch [6/20], Step [8/15], Loss: 0.6692\n",
            "Epoch [6/20], Step [15/15], Loss: 0.6986\n",
            "Epoch [7/20], Step [1/15], Loss: 0.6013\n",
            "Epoch [7/20], Step [8/15], Loss: 0.4708\n",
            "Epoch [7/20], Step [15/15], Loss: 0.5227\n",
            "Epoch [8/20], Step [1/15], Loss: 0.5335\n",
            "Epoch [8/20], Step [8/15], Loss: 0.4859\n",
            "Epoch [8/20], Step [15/15], Loss: 0.5587\n",
            "Epoch [9/20], Step [1/15], Loss: 0.4756\n",
            "Epoch [9/20], Step [8/15], Loss: 0.4323\n",
            "Epoch [9/20], Step [15/15], Loss: 0.5145\n",
            "Epoch [10/20], Step [1/15], Loss: 0.3750\n",
            "Epoch [10/20], Step [8/15], Loss: 0.3880\n",
            "Epoch [10/20], Step [15/15], Loss: 0.2625\n",
            "Epoch [11/20], Step [1/15], Loss: 0.3419\n",
            "Epoch [11/20], Step [8/15], Loss: 0.3070\n",
            "Epoch [11/20], Step [15/15], Loss: 0.4123\n",
            "Epoch [12/20], Step [1/15], Loss: 0.3041\n",
            "Epoch [12/20], Step [8/15], Loss: 0.2493\n",
            "Epoch [12/20], Step [15/15], Loss: 0.4585\n",
            "Epoch [13/20], Step [1/15], Loss: 0.2580\n",
            "Epoch [13/20], Step [8/15], Loss: 0.2877\n",
            "Epoch [13/20], Step [15/15], Loss: 0.2841\n",
            "Epoch [14/20], Step [1/15], Loss: 0.2462\n",
            "Epoch [14/20], Step [8/15], Loss: 0.2765\n",
            "Epoch [14/20], Step [15/15], Loss: 0.2207\n",
            "Epoch [15/20], Step [1/15], Loss: 0.1962\n",
            "Epoch [15/20], Step [8/15], Loss: 0.2392\n",
            "Epoch [15/20], Step [15/15], Loss: 0.1455\n",
            "Epoch [16/20], Step [1/15], Loss: 0.1667\n",
            "Epoch [16/20], Step [8/15], Loss: 0.1999\n",
            "Epoch [16/20], Step [15/15], Loss: 0.1463\n",
            "Epoch [17/20], Step [1/15], Loss: 0.1151\n",
            "Epoch [17/20], Step [8/15], Loss: 0.0917\n",
            "Epoch [17/20], Step [15/15], Loss: 0.2405\n",
            "Epoch [18/20], Step [1/15], Loss: 0.1220\n",
            "Epoch [18/20], Step [8/15], Loss: 0.1600\n",
            "Epoch [18/20], Step [15/15], Loss: 0.1204\n",
            "Epoch [19/20], Step [1/15], Loss: 0.2857\n",
            "Epoch [19/20], Step [8/15], Loss: 0.1714\n",
            "Epoch [19/20], Step [15/15], Loss: 0.1001\n",
            "Epoch [20/20], Step [1/15], Loss: 0.1395\n",
            "Epoch [20/20], Step [8/15], Loss: 0.1516\n",
            "Epoch [20/20], Step [15/15], Loss: 0.0751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Validation loop\n",
        "with torch.no_grad():\n",
        "    for visual_data, acoustic_data, lexical_data, labels in val_loader:\n",
        "        outputs = model(visual_data, acoustic_data, lexical_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Validation Accuracy of the model: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DGXRzhh7i93",
        "outputId": "31392a0f-8475-4b6f-bd85-2906d24a5657"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy of the model: 63.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion Classification and Grid Search: The project entails classifying emotions into four distinct classes. Various classifiers are employed, guided by the feature vectors derived from temporal modeling. Through Grid Search, the parameters of these classifiers are optimized over a defined range, ensuring the most accurate results."
      ],
      "metadata": {
        "id": "cEnK9S7z79tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another approach: Much faster, but much less accurate\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']}\n",
        "\n",
        "# Load labels\n",
        "labels = df['emotion_labels'].values\n",
        "\n",
        "# Split the data into training and testing sets for each modality\n",
        "X_train_visual, X_test_visual, y_train, y_test = train_test_split(visual_features_pooled, labels, test_size=0.2, random_state=42)\n",
        "X_train_acoustic, X_test_acoustic, _, _ = train_test_split(acoustic_features_pooled, labels, test_size=0.2, random_state=42)\n",
        "X_train_lexical, X_test_lexical, _, _ = train_test_split(lexical_features_pooled, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of the classifier for each modality\n",
        "svm_visual = GridSearchCV(SVC(class_weight='balanced'), param_grid, refit=True)\n",
        "svm_acoustic = GridSearchCV(SVC(class_weight='balanced'), param_grid, refit=True)\n",
        "svm_lexical = GridSearchCV(SVC(class_weight='balanced'), param_grid, refit=True)"
      ],
      "metadata": {
        "id": "aWZNeHtlCBoD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier for each modality and print the best parameters\n",
        "svm_visual.fit(X_train_visual, y_train)\n",
        "print(f\"Best parameters for visual: {svm_visual.best_params_}\")\n",
        "\n",
        "svm_acoustic.fit(X_train_acoustic, y_train)\n",
        "print(f\"Best parameters for acoustic: {svm_acoustic.best_params_}\")\n",
        "\n",
        "svm_lexical.fit(X_train_lexical, y_train)\n",
        "print(f\"Best parameters for lexical: {svm_lexical.best_params_}\")\n",
        "\n",
        "# Test the classifier for each modality\n",
        "score_visual = svm_visual.score(X_test_visual, y_test)\n",
        "print(f\"Model Accuracy for visual: {score_visual}\")\n",
        "\n",
        "score_acoustic = svm_acoustic.score(X_test_acoustic, y_test)\n",
        "print(f\"Model Accuracy for acoustic: {score_acoustic}\")\n",
        "\n",
        "score_lexical = svm_lexical.score(X_test_lexical, y_test)\n",
        "print(f\"Model Accuracy for lexical: {score_lexical}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvit9iQ3Cpdr",
        "outputId": "a9d5f0d1-1770-4a39-8e2a-4a9e8bf3e935"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for visual: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best parameters for acoustic: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best parameters for lexical: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Model Accuracy for visual: 0.5335820895522388\n",
            "Model Accuracy for acoustic: 0.5335820895522388\n",
            "Model Accuracy for lexical: 0.291044776119403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusion Techniques: To achieve a comprehensive understanding of emotions, both early fusion (feature concatenation) and late fusion (majority voting) techniques are adopted on multimodal data. This allows for the integration of different modalities at various stages of processing"
      ],
      "metadata": {
        "id": "YD3nOf3C9xyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the generic \"best\" parameters to the most frequently occuring result\n",
        "best_C = 10\n",
        "best_gamma = .01\n",
        "\n",
        "# Early Fusion: Concatenating the features\n",
        "early_fusion = np.concatenate((visual_features_pooled, acoustic_features_pooled, lexical_features_pooled), axis=1)\n",
        "\n",
        "# Train on early_fusion dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(early_fusion, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of the classifier\n",
        "svm = SVC(class_weight='balanced', C=best_C, gamma=best_gamma, kernel='rbf')\n",
        "\n",
        "# Train the classifier\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "y_pred = svm.predict(X_test)"
      ],
      "metadata": {
        "id": "ueZYBMsBCrWd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Imbalance: Class imbalance is a significant challenge in classification tasks. This program uses the 'class_weight' parameter of the SVM model to handle class imbalance. This method basically applies different weights to different classes. In 'balanced' mode, classes are automatically adjusted inverse to their frequency. A confusion matrix reveals how the model deals with each class."
      ],
      "metadata": {
        "id": "djqhmDIg8Wxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Normalize confusion matrix\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(cm_norm, annot=True, cmap='Blues', fmt=\".3f\", xticklabels=np.unique(labels), yticklabels=np.unique(labels))\n",
        "\n",
        "plt.title('Confusion matrix')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "RhONAt1rw1B-",
        "outputId": "af0e7058-8263-4128-f1c8-fdfcd82b7cca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this confusion matrix you can see that the main difficulty with this model is differentiating between a charged emotion(happy, sad, angry) and neutral. Angry and sad data pretty much only encounters problems with neutrality, while happiness is mistaken for neutrality very often, which probably accounts for a lot of the error in the model. Meanwhile, neutrality is actually classified very well. This confusion matrix reveals that happiness accounts for most of the deficiency of the models."
      ],
      "metadata": {
        "id": "bgJKH8uzKHj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = svm.score(X_test, y_test)\n",
        "print(f\"Model Accuracy: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPuBWoSJw5v3",
        "outputId": "bc16759f-c3ea-47fe-a95c-8620c10149bc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.6343283582089553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the individual feature sets into training and testing sets\n",
        "X_train_visual, X_test_visual, _, _ = train_test_split(visual_features_pooled, labels, test_size=0.2, random_state=42)\n",
        "X_train_acoustic, X_test_acoustic, _, _ = train_test_split(acoustic_features_pooled, labels, test_size=0.2, random_state=42)\n",
        "X_train_lexical, X_test_lexical, _, _ = train_test_split(lexical_features_pooled, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jq4dlwZuJ807"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best parameters\n",
        "best_parameters_visual = svm_visual.best_params_\n",
        "best_C_visual = best_parameters_visual['C']\n",
        "best_gamma_visual = best_parameters_visual['gamma']\n",
        "\n",
        "best_parameters_acoustic = svm_acoustic.best_params_\n",
        "best_C_acoustic = best_parameters_acoustic['C']\n",
        "best_gamma_acoustic = best_parameters_acoustic['gamma']\n",
        "\n",
        "best_parameters_lexical = svm_lexical.best_params_\n",
        "best_C_lexical = best_parameters_lexical['C']\n",
        "best_gamma_lexical = best_parameters_lexical['gamma']"
      ],
      "metadata": {
        "id": "20iO4l5yWrYH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create instances of the classifier\n",
        "svm_visual = SVC(class_weight='balanced', probability=True, C=best_C_visual, gamma=best_gamma_visual, kernel='rbf')\n",
        "svm_acoustic = SVC(class_weight='balanced', probability=True, C=best_C_acoustic, gamma=best_gamma_acoustic, kernel='rbf')\n",
        "svm_lexical = SVC(class_weight='balanced', probability=True, C=best_C_lexical, gamma=best_gamma_lexical, kernel='rbf')\n",
        "\n",
        "# Train the classifiers\n",
        "svm_visual.fit(X_train_visual, y_train)\n",
        "svm_acoustic.fit(X_train_acoustic, y_train)\n",
        "svm_lexical.fit(X_train_lexical, y_train)\n",
        "\n",
        "# Predict the class probabilities\n",
        "proba_visual = svm_visual.predict_proba(X_test_visual)\n",
        "proba_acoustic = svm_acoustic.predict_proba(X_test_acoustic)\n",
        "proba_lexical = svm_lexical.predict_proba(X_test_lexical)\n",
        "\n",
        "# Average the probabilities\n",
        "proba_average = (proba_visual + proba_acoustic + proba_lexical) / 3\n",
        "\n",
        "# Get the class with the highest probability\n",
        "predictions = np.argmax(proba_average, axis=1)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRsIgl2ECtMi",
        "outputId": "17e50c23-f51a-4c98-eac4-2bbc1f7c3337"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.6231343283582089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results Reporting and Cross Validation: The classification results on individual modalities - vision, speech, and text - are evaluated using the F1-micro metric to ensure a balanced measure of precision and recall. A 10-fold subject-independent cross-validation scheme is adopted to validate these findings and prevent overfitting."
      ],
      "metadata": {
        "id": "K5I_62228FZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "# Create a scorer for f1-micro\n",
        "f1_micro_scorer = make_scorer(f1_score, average='micro')\n",
        "\n",
        "# Create an instance of the classifier\n",
        "svm = SVC(class_weight='balanced', C=best_C, gamma=best_gamma, kernel='rbf')\n",
        "\n",
        "# Perform 10-fold cross-validation and print the average F1-micro score\n",
        "scores = cross_val_score(svm, early_fusion, labels, cv=10, scoring=f1_micro_scorer)\n",
        "print(f\"Average F1-micro score: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw-4DB9pC0pV",
        "outputId": "8a795138-3c68-44f9-e22c-ff83799dd579"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average F1-micro score: 0.5202109751991919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the classifier for visual data\n",
        "svm = SVC(class_weight='balanced', C=best_C_visual, gamma=best_gamma_visual, kernel='rbf')\n",
        "\n",
        "# Perform 10-fold cross-validation and print the average F1-micro score\n",
        "scores = cross_val_score(svm, visual_features_pooled, labels, cv=10, scoring=f1_micro_scorer)\n",
        "print(f\"Average F1-micro score for visual: {scores.mean()}\")\n",
        "\n",
        "# Create an instance of the classifier for acoustic data\n",
        "svm = SVC(class_weight='balanced', C=best_C_acoustic, gamma=best_gamma_acoustic, kernel='rbf')\n",
        "\n",
        "# Perform 10-fold cross-validation and print the average F1-micro score\n",
        "scores = cross_val_score(svm, acoustic_features_pooled, labels, cv=10, scoring=f1_micro_scorer)\n",
        "print(f\"Average F1-micro score for acoustic: {scores.mean()}\")\n",
        "\n",
        "# Create an instance of the classifier for lexical data\n",
        "svm = SVC(class_weight='balanced', C=best_C_lexical, gamma=best_gamma_lexical, kernel='rbf')\n",
        "\n",
        "# Perform 10-fold cross-validation and print the average F1-micro score\n",
        "scores = cross_val_score(svm, lexical_features_pooled, labels, cv=10, scoring=f1_micro_scorer)\n",
        "print(f\"Average F1-micro score for lexical: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke1oWONxtFEd",
        "outputId": "9a0a080d-bc33-48fa-e5a3-f7dab29ad486"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average F1-micro score for visual: 0.40941532936819663\n",
            "Average F1-micro score for acoustic: 0.5216193468746493\n",
            "Average F1-micro score for lexical: 0.26361800022444176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the modalities: The best parameters for the SVM classifiers have been found successfully using grid search. Interestingly, all three modalities (visual, acoustic, and lexical) share the same best 'C' parameter and 'kernel' type. However, the 'gamma' value differs for the lexical features, which may imply different data characteristics. In this same vein, the model accuracy across three different modalities (visual, acoustic, and lexical) varies. The visual and acoustic features yield the same accuracy of approximately 53.4%, while the lexical features result in a significantly lower accuracy of 29.1%. This suggests that the lexical features may not be as effective in predicting the emotion labels in this case, or the SVM classifier may not be the best model for the lexical features."
      ],
      "metadata": {
        "id": "PDHRQOh25cnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On performance: When the SVM is trained on the concatenated features in early fusion, the accuracy increases to approximately 63.4%. This suggests that combining the features provides more information for the classifier to make a decision and results in a better model performance. Additionally, the F1-micro score, a metric that considers both precision and recall, is approximately 52.0%. This suggests that there is still room for improving the model's performance."
      ],
      "metadata": {
        "id": "jz1njMAi6Ffw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On comparing unimodal and multimodal classification: In this program, both types of classification are used. The accuracy for the unimodal classification is much lower than the multimodal accuracy, and the best unimodal F1-micro score pretty much ties the multimodal F1-micro score. From this, it is evident that the multimodal classification performs better. This is because the modalities should be represented and aligned in a way that they combine to contribute emergent, complementary knowledge."
      ],
      "metadata": {
        "id": "4fGJv1pEGm1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test data\n",
        "for data in test_loader:\n",
        "    # Unpack the data\n",
        "    visual_inputs, acoustic_inputs, lexical_inputs, labels = data\n",
        "\n",
        "    # Get the model's predictions\n",
        "    outputs = model(visual_inputs, acoustic_inputs, lexical_inputs)\n",
        "\n",
        "    # Convert the predictions to the class with the highest probability\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update total and correct\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f'GRU Model Accuracy: {accuracy * 100}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9oZgfvxfgnK",
        "outputId": "684210d8-05a0-4e14-fe57-63c88135172d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU Model Accuracy: 60.19900497512438%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the GRU layer model seems to perform similarly to the early fusion and late fusion approaches, with all scores wavering around 63% for most runs. The two differ in runtime, however, with the GRU model being much slower."
      ],
      "metadata": {
        "id": "PLBYDsT4IJZc"
      }
    }
  ]
}